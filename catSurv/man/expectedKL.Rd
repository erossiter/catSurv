% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{expectedKL}
\alias{expectedKL}
\title{Expected Kullback-Leibeler information}
\usage{
expectedKL(cat_df, item)
}
\arguments{
\item{cat_df}{An object of \code{Cat} class}

\item{item}{An integer indicating the index of the question}
}
\value{
A value indicating the KL information for the desired item, given the current answer profile and ability estimate.
}
\description{
Calculate the expected Kullback-Leibeler information
}
\details{
The Kullback-Leibeler information is defined as follows.  Let \eqn{\theta_0} be the true value of the parameter and \eqn{\hat{\theta}} be our current best guess based on the data we have collected so far \deqn{\mathbf{y}_{k-1}}{y_{k-1}}.
The KL item information for item \eqn{k} is:

\deqn{K_k(\hat{\theta} ; \theta_0) \equiv E_{\theta_0}\log\Big[\frac{L(\theta_0|\mathbf{y}_{k-1}, y_k)}{L(\hat{\theta}|\mathbf{y}_{k-1})} \Big]}{K_k(\hat{\theta} ; \theta_0) \equiv E_{\theta_0}log[(L(\theta_0| y_{k-1}, y_k)/(L(\hat{\theta}| y_{k-1}))]}

 Since \eqn{\theta_0} is unknow, the expected value of the KL information is estimated for each item:

 \deqn{K_k(\hat{\theta};\theta_0) = \int^{\hat{\theta}+\delta}_{\hat{\theta}-\delta}\log\Big[\frac{L(\theta_0|\mathbf{y}_{k-1}, y_k)}{L(\hat{\theta}|\mathbf{y}_{k-1})} \Big] d\theta_0}{K_k(\hat{\theta};\theta_0) = \int^{\hat{\theta} + \delta}_{\hat{\theta} - \delta} log[(L(\theta_0|y_{k-1}, y_k)/(L(\hat{\theta}|y_{k-1}))] d\theta_0}

 where \deqn{\delta = z(I(\hat{\theta}))^{-1/2}}{\delta = z(I(\hat{\theta}))^{-1/2}},  \eqn{I(\hat{\theta})} is the test information evaluated at \eqn{\hat{\theta}} for respondent \eqn{j}, and \eqn{z} is a user specified z-value.  
 
 Binary details:

 Due to the conditional independence assumption, we only need to calculate the expected value for potential new items.


 \deqn{\int_{\hat{\theta}-\delta}^{\hat{\theta}+\delta} \Big( P(y_{ij} =
  1|\theta_0)\log\Big[\frac{P(y_{ij}=1|\theta_0)}{P(y_{ij}=1|\hat{\theta})} \Big] + P(y_{ij} =
  0|\theta_0)\log\Big[\frac{P(y_{ij}=0|\theta_0)}{P(y_{ij}=0|\hat{\theta})} \Big] \Big) d\theta_0}
  {\int_{\hat{\theta} - \delta}^{\hat{\theta} + \delta} (P(y_ij =
  1| \theta_0) log[(P(y_ij = 1| \theta_0))/(P(y_ij = 1| \hat{\theta}))] + P(y_ij =
  0| \theta_0) log[(P(y_ij = 0| \theta_0))/(P(y_ij = 0| \hat{\theta}))]) d\theta_0}

\deqn{\int_{\hat{\theta}-\delta}^{\hat{\theta}+\delta} \Big( P(y_{ij} =
  1|\theta_0)\big(\log(P(y_{ij}=1|\theta_0)) - \log(P(y_{ij}=1|\hat{\theta}))\big) \Big) \\~~~~~~~ + \Big( P(y_{ij} =
  0|\theta_0)\big(\log(P(y_{ij}=0|\theta_0)) - \log(P(y_{ij}=0|\hat{\theta}))\big) \Big) d\theta_0}{\int_{\hat{\theta} - \delta}^{\hat{\theta} + \delta} (P(y_ij =
  1| \theta_0) (log(P(y_ij = 1| \theta_0)) - log(P(y_ij = 1| \hat{\theta})))) + (P(y_ij =
  0| \theta_0) (log(P(y_ij = 0| \theta_0)) - log(P(y_ij = 0| \hat{\theta})))) d\theta_0}

 Categorical details:

 \deqn{\int_{\hat{\theta}-\delta}^{\hat{\theta}+\delta} \sum_k\Big(
    P(y_{ij}=k|\theta_0)\big(\log(P(y_{ij}=k|\theta_0))- \log(P(y_{ij}=k|\hat{\theta})) \big)\Big) d\theta_0}{\int_{\hat{\theta} - \delta}^{\hat{\theta} + \delta} 
    \sum_k(P(y_ij = k| \theta_0) (log(P(y_ij = k| \theta_0)) - log(P(y_ij = k| \hat{\theta})))) d\theta_0}
}
\examples{

## binary (ltm)

 data("npi")
 ltm_data <- npi[1:100, ]
 ltm_cat <- ltmCat(ltm_data, quadraturePoints = 100)
 ltm_cat@answers <- as.numeric(ltm_data[1,])
 
 expectedKL(ltm_cat, 1)
 
## binary (tpm)

 data("AMTknowledge")
 tpm_data <- AMTknowledge[1:100, ]
 tpm_cat <- tpmCat(tpm_data, quadraturePoints = 100)
 tpm_cat@answers <- as.numeric(tpm_data[1,])
 
 expectedKL(tpm_cat, 1)

## categorical (grm) 

 data("nfc")
 poly_data <- nfc[1:100, ]
 poly_cat <- grmCat(poly_data, quadraturePoints = 100)
 poly_cat@answers <- as.numeric(poly_data[1,])
 
 expectedKL(poly_cat, 1)

}
\seealso{
\code{\link{estimateTheta}} for calculation of \eqn{\theta};
  \code{\link{likelihoodKL}} and/or \code{\link{posteriorKL}} for alternative KL methods
}

